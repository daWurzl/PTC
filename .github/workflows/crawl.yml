# Name des Workflows, wie er in GitHub Actions angezeigt wird
name: Zeitsteuerung

# Wann der Workflow ausgelöst wird:
on:
  schedule:
    - cron: "0 */4 * * *"   # Alle 4 Stunden um :00 Uhr UTC
  workflow_dispatch:        # Manuelle Auslösung über GitHub-UI

jobs:
  crawl:
    runs-on: ubuntu-latest   # Nutzt die neueste Ubuntu-VM von GitHub

    timeout-minutes: 60      # Maximal 60 Minuten Laufzeit für den Job

    steps:
      # 1. Repository auschecken (Code herunterladen)
      - name: Checkout Code
        uses: actions/checkout@v4

      # 2. Python 3.11 Umgebung einrichten
      - name: Set up Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      # 3. Abhängigkeiten installieren (pip, alle benötigten Pakete)
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install aiohttp beautifulsoup4 pydantic python-dotenv playwright

      # 4. Playwright-Browser (Chromium) und Systemabhängigkeiten installieren
      - name: Install Playwright browsers
        run: playwright install --with-deps chromium

      # 5. Datenverzeichnis für Ausgabedateien anlegen
      - name: Create data directory
        run: mkdir -p data

      # 6. Crawler ausführen (python crawler/crawl.py)
      - name: Run crawler
        run: python crawler/crawl.py
        env:
          PYTHONUNBUFFERED: 1   # Sofortige Ausgabe von Logs

      # 7. Ergebnisse und Logs als Artefakt hochladen (z.B. für Download/Debugging)
      - name: Upload logs and results
        if: always()  # Führt diesen Schritt immer aus, auch bei Fehlern
        uses: actions/upload-artifact@v4
        with:
          name: crawler-artifacts
          path: |
            data/results.csv
            crawler.log
